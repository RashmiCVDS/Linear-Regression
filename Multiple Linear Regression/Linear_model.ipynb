{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.linalg import pinv\n",
    "from IPython.display import display, Math, Latex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Statistics, Linear regression is a linear approach which models the relationship between a dependent variable (continuous) and one or more independent variables. Linear regression is also called as Least squares regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the dependent variable, Y  and the independent variables, X1 and X2."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![multiple_linear.png](multiple_linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have multiple independent variables $x-{1}$, $x_{2}$,....., $x_{n}$.\n",
    "\n",
    "Now, $f(x)$ = $b_{0}$ + $b_{1}x_{1}$ + $b_{2}x_{2}$ + ... + $b_{m}x_{m}$\n",
    "\n",
    "$y_{0}$ = $b_{0}$ + $b_{1}x_{11}$ + $b_{2}x_{12}$ + ... + $b_{m}x_{1m}$\n",
    "\n",
    "$y_{1}$ = $b_{0}$ + $b_{1}x_{21}$ + $b_{2}x_{22}$ + ... + $b_{m}x_{2m}$\n",
    "\n",
    "$y_{2}$ = $b_{0}$ + $b_{1}x_{21}$ + $b_{2}x_{22}$ + ... + $b_{m}x_{2m}$\n",
    "\n",
    "$y_{n+1}$ = $b_{0}$ + $b_{1}x_{m (n+1)}$ + $b_{2}x_{mn}$ + ... + $b_{m}x_{mn}$\n",
    "\n",
    "\n",
    "\n",
    "We have many equations, for each of them we should find normal equations, instead we consider matrices which are used for computational efficiency. \n",
    "\n",
    "$ X = \\left[ \\begin{array}{cccc}\n",
    "1 & x_{11} & x_{12} & \\ldots & x_{1m} \\\\\n",
    "1 & x_{21} & x_{22} & \\ldots & x_{2m} \\\\\n",
    ".  & .   &    .    &          &      . \\\\\n",
    ".  & .   &    .   &           &     . \\\\\n",
    "1 & x_{(n+1)m} & x_{(n+1)m} & \\ldots & x_{(n+1)m} \\\\ \\end{array} \\right ] $\n",
    "\n",
    "$Y = \\left[ \\begin{array}{cccc}\n",
    "y_{0} \\\\\n",
    "y_{1} \\\\\n",
    "y_{2} \\\\\n",
    "    . \\\\\n",
    "    . \\\\\n",
    "y_{(n+1)} \\\\ \\end{array} \\right]$\n",
    "\n",
    "$B = \\left[ \\begin{array}{cccc}\n",
    "b_{0} \\\\\n",
    "b_{1} \\\\\n",
    "b_{2} \\\\\n",
    "    . \\\\\n",
    "    . \\\\\n",
    "b_{(n+1)} \\\\ \\end{array} \\right]$\n",
    "\n",
    "$X$ = $ (n+1)$ x $m$  matrix , $Y$ = $(n+1)$ x $1$     matrix , $B$ = $(n+1)$ x$ 1 $   matrix \n",
    "\n",
    "\n",
    "$ Y = XB $\n",
    "\n",
    "$ \\hat{Y} = X \\hat{B}$ ------------[1]\n",
    "\n",
    "Our objective is to reduce the error function, which is as follows\n",
    "\n",
    "$ e = (Y - \\hat{Yi})^2 $\n",
    "\n",
    "According to matrices, we know that $ A^2 = A^\\top A $\n",
    "\n",
    "$(Y - \\hat{Yi})^2 = (Y - \\hat{Yi})^\\top (Y - \\hat{Yi}) $\n",
    "\n",
    "substitute [1] in above we get \n",
    "\n",
    "$ = (Y -  X \\hat{B})^\\top (Y - X \\hat{B})$\n",
    "\n",
    "$ = (Y^\\top -   \\hat{B}^\\top X^\\top ) (Y -  X \\hat{B})) $\n",
    "\n",
    "$ =  Y^\\top Y - Y^\\top X \\hat{B} - \\hat{B}^\\top X^\\top Y + \\hat{B}^\\top X^\\top X \\hat{B} $\n",
    "\n",
    "Now we take the partial derivative of the above equation and equate it to 0\n",
    "\n",
    "matrix differentiation, \n",
    "\n",
    "$ \\frac{\\partial}{\\partial x} A = 0 $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial x} Ax = A  $\n",
    "\n",
    "$ \\frac{\\partial}{\\partial x} xA = A^\\top $\n",
    "\n",
    "$  \\frac{\\partial}{\\partial x} x^\\top A x = 2 x^\\top A $\n",
    "\n",
    "We use the above differentiations in our equation\n",
    "\n",
    "$ \\frac{\\partial}{\\partial \\hat{B}} ( Y^\\top Y - Y^\\top X \\hat{B} - \\hat{B}^\\top X^\\top Y + \\hat{B}^\\top X^\\top X \\hat{B})  = 0 $\n",
    "\n",
    "$ 0 - Y^\\top X - ( X^\\top Y)^\\top + 2 \\hat{B}^\\top X^\\top X = 0 $\n",
    "\n",
    "$ 2 \\hat{B}^\\top X^\\top X =  Y^\\top X + ( X^\\top Y)^\\top $ \n",
    "\n",
    "we know that $  ( X^\\top Y)^\\top =  Y^\\top X  $\n",
    "\n",
    "$ \\hat{B}^\\top X^\\top X =  Y^\\top X $\n",
    "\n",
    "$ \\hat{B}^\\top = Y^\\top X  (X^\\top X)^ {-1}  $\n",
    "\n",
    "$ \\hat{B} = (X^\\top X)^{ -1} X^\\top Y $\n",
    "\n",
    "We now got the $\\hat{B} =  b_{0},b_{1},b_{2},....,b_{n+1} $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear model function \n",
    "def lm(x,y):\n",
    "    x = np.matrix(x)\n",
    "    y = np.matrix(y)\n",
    "    a =  pinv(np.transpose(x)*(x))*np.transpose(x)* np.transpose(y)\n",
    "    return a # which gives us the slope values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Predictions\n",
    "def pred(model,test_data):\n",
    "    test_data = np.matrix(test_data)\n",
    "    z = test_data * lm(x,y)\n",
    "    return z "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Toy dataset\n",
    "data = pd.read_csv('d.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = data.X7 # Target \n",
    "x = data.drop(['X7'],1) #Independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train and Test split :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.2,random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = lm(xtrain,ytrain) # Function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z = pred(a,xtest) # prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.143689135274693"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(np.array(z),ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparision with gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xtrain,ytrain) # training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = model.predict(xtest) # prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because the independent variables are not standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.224834334203972"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.mean_squared_error(a,ytest) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
